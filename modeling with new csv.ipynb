{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf986e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_validate\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4691153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>WINDOW_START_LOCAL</th>\n",
       "      <th>WINDOW_END_LOCAL</th>\n",
       "      <th>event_cutoff_by</th>\n",
       "      <th>SALES_OFFICE</th>\n",
       "      <th>SHIPPING_CONDITIONS_DESC</th>\n",
       "      <th>WEEK_DAY_OF_ANCHOR_DATE</th>\n",
       "      <th>WINDOW_FREQUENCY</th>\n",
       "      <th>DISTRIBUTION_MODE_DESC</th>\n",
       "      <th>...</th>\n",
       "      <th>mode_event_os</th>\n",
       "      <th>minutes_of_first_event_and_window_end</th>\n",
       "      <th>cutoff_amount</th>\n",
       "      <th>total_events</th>\n",
       "      <th>cart_page_views</th>\n",
       "      <th>product_page_views</th>\n",
       "      <th>order_page_views</th>\n",
       "      <th>visited_cart</th>\n",
       "      <th>visited_product</th>\n",
       "      <th>visited_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>500245685</td>\n",
       "      <td>2025-02-17 17:00:00</td>\n",
       "      <td>2025-02-24 17:00:00</td>\n",
       "      <td>2025-02-23 11:02:29.219700000</td>\n",
       "      <td>G111</td>\n",
       "      <td>48 Hours</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>OFS</td>\n",
       "      <td>...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>5924.706600</td>\n",
       "      <td>1777.411980</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>500245685</td>\n",
       "      <td>2025-03-17 17:00:00</td>\n",
       "      <td>2025-03-24 17:00:00</td>\n",
       "      <td>2025-03-22 19:49:23.863200000</td>\n",
       "      <td>G111</td>\n",
       "      <td>48 Hours</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>OFS</td>\n",
       "      <td>...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>9034.144367</td>\n",
       "      <td>2710.243310</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>500245685</td>\n",
       "      <td>2025-04-14 17:00:00</td>\n",
       "      <td>2025-04-21 17:00:00</td>\n",
       "      <td>2025-04-20 11:20:52.683900000</td>\n",
       "      <td>G111</td>\n",
       "      <td>48 Hours</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>OFS</td>\n",
       "      <td>...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>5927.056417</td>\n",
       "      <td>1778.116925</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>500245685</td>\n",
       "      <td>2025-04-28 17:00:00</td>\n",
       "      <td>2025-05-05 17:00:00</td>\n",
       "      <td>2025-05-04 18:24:35.996400000</td>\n",
       "      <td>G111</td>\n",
       "      <td>48 Hours</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>OFS</td>\n",
       "      <td>...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>4507.125967</td>\n",
       "      <td>1352.137790</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>500245738</td>\n",
       "      <td>2024-11-20 17:00:00</td>\n",
       "      <td>2024-11-27 17:00:00</td>\n",
       "      <td>2024-11-26 03:25:05.337600000</td>\n",
       "      <td>G111</td>\n",
       "      <td>48 Hours</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>OFS</td>\n",
       "      <td>...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>7515.126033</td>\n",
       "      <td>2254.537810</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CUSTOMER_ID   WINDOW_START_LOCAL     WINDOW_END_LOCAL  \\\n",
       "0           0    500245685  2025-02-17 17:00:00  2025-02-24 17:00:00   \n",
       "1           1    500245685  2025-03-17 17:00:00  2025-03-24 17:00:00   \n",
       "2           2    500245685  2025-04-14 17:00:00  2025-04-21 17:00:00   \n",
       "3           3    500245685  2025-04-28 17:00:00  2025-05-05 17:00:00   \n",
       "4           4    500245738  2024-11-20 17:00:00  2024-11-27 17:00:00   \n",
       "\n",
       "                 event_cutoff_by SALES_OFFICE SHIPPING_CONDITIONS_DESC  \\\n",
       "0  2025-02-23 11:02:29.219700000         G111                 48 Hours   \n",
       "1  2025-03-22 19:49:23.863200000         G111                 48 Hours   \n",
       "2  2025-04-20 11:20:52.683900000         G111                 48 Hours   \n",
       "3  2025-05-04 18:24:35.996400000         G111                 48 Hours   \n",
       "4  2024-11-26 03:25:05.337600000         G111                 48 Hours   \n",
       "\n",
       "  WEEK_DAY_OF_ANCHOR_DATE  WINDOW_FREQUENCY DISTRIBUTION_MODE_DESC  ...  \\\n",
       "0                  Monday                 7                    OFS  ...   \n",
       "1                  Monday                 7                    OFS  ...   \n",
       "2                  Monday                 7                    OFS  ...   \n",
       "3                  Monday                 7                    OFS  ...   \n",
       "4               Wednesday                 7                    OFS  ...   \n",
       "\n",
       "  mode_event_os  minutes_of_first_event_and_window_end cutoff_amount  \\\n",
       "0       Windows                            5924.706600   1777.411980   \n",
       "1       Windows                            9034.144367   2710.243310   \n",
       "2       Windows                            5927.056417   1778.116925   \n",
       "3       Windows                            4507.125967   1352.137790   \n",
       "4       Windows                            7515.126033   2254.537810   \n",
       "\n",
       "   total_events  cart_page_views  product_page_views  order_page_views  \\\n",
       "0             7                5                   0                 0   \n",
       "1             2                0                   0                 0   \n",
       "2             3                1                   0                 0   \n",
       "3             2                0                   0                 0   \n",
       "4             2                0                   0                 1   \n",
       "\n",
       "   visited_cart  visited_product visited_order  \n",
       "0             1                0             0  \n",
       "1             0                0             0  \n",
       "2             1                0             0  \n",
       "3             0                0             0  \n",
       "4             0                0             1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('modeling_data.csv') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0ed093",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['ABANDONED_CART','CUSTOMER_ID'])\n",
    "y = data['ABANDONED_CART']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.3,\n",
    "    random_state=12345,\n",
    "    stratify=y \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07135da6",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62ec868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: your training data\n",
    "x_train = x_train.copy()\n",
    "\n",
    "# Identify datetime-like columns\n",
    "dt_cols = x_train.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']).columns\n",
    "\n",
    "# Convert datetime columns to numeric (days since min date per column)\n",
    "for c in dt_cols:\n",
    "    # Ensure all are parsed as datetimes\n",
    "    x_train[c] = pd.to_datetime(x_train[c], errors='coerce')\n",
    "\n",
    "    # Choose a reference (anchor) — earliest date in train\n",
    "    anchor = x_train[c].min()\n",
    "\n",
    "    # Convert to days since anchor\n",
    "    x_train[c] = (x_train[c] - anchor).dt.total_seconds() / 86400.0  # seconds → days\n",
    "\n",
    "# Repeat the same transformation for x_test using the same anchor values\n",
    "for c in dt_cols:\n",
    "    x_test[c] = pd.to_datetime(x_test[c], errors='coerce')\n",
    "    x_test[c] = (x_test[c] - anchor).dt.total_seconds() / 86400.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120f9f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8887\n",
      "Precision: 0.7342\n",
      "Recall   : 0.3505\n",
      "F1 Score : 0.4745\n",
      "AUC      : 0.8331\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94      4759\n",
      "         1.0       0.73      0.35      0.47       796\n",
      "\n",
      "    accuracy                           0.89      5555\n",
      "   macro avg       0.82      0.66      0.71      5555\n",
      "weighted avg       0.88      0.89      0.87      5555\n",
      "\n",
      "\n",
      "Confusion Matrix (counts):\n",
      " [[4658  101]\n",
      " [ 517  279]]\n",
      "\n",
      "Confusion Matrix (proportions by true class):\n",
      " [[0.979 0.021]\n",
      " [0.649 0.351]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) One-hot encode any remaining non-numeric columns\n",
    "x_train_enc = pd.get_dummies(x_train, drop_first=True)\n",
    "x_test_enc  = pd.get_dummies(x_test,  drop_first=True)\n",
    "\n",
    "# 2) Align columns (ensure same features in train & test)\n",
    "x_test_enc = x_test_enc.reindex(columns=x_train_enc.columns, fill_value=np.nan)\n",
    "\n",
    "# 3) Simple impute: fill NaNs with train medians\n",
    "medians = x_train_enc.median(numeric_only=True)\n",
    "x_train_enc = x_train_enc.fillna(medians)\n",
    "x_test_enc  = x_test_enc.fillna(medians)\n",
    "\n",
    "# 4) Fit logistic regression\n",
    "model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "model.fit(x_train_enc, y_train)\n",
    "\n",
    "# 5) Predict\n",
    "y_pred  = model.predict(x_test_enc)\n",
    "y_proba = model.predict_proba(x_test_enc)[:, 1]\n",
    "\n",
    "# 6) Metrics\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc  = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(f\"AUC      : {auc:.4f}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# 7) Confusion matrix (counts + normalized)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix (counts):\\n\", cm)\n",
    "\n",
    "cm_norm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(\"\\nConfusion Matrix (proportions by true class):\\n\", np.round(cm_norm, 3))\n",
    "\n",
    "# Optional: plot counts matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d', colorbar=False)\n",
    "plt.title('Confusion Matrix (Counts)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5c737",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8696a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best params: {'class_weight': 'balanced_subsample', 'max_depth': 12, 'min_samples_leaf': 5, 'n_estimators': 500}\n",
      "CV best recall: 0.3536\n",
      "Chosen F2-optimal threshold for best RF: 0.330\n",
      "\n",
      "=== Comparison Table ===\n",
      "   Model@Threshold  Accuracy  Precision   Recall       F1      AUC   TN   FP  FN  TP\n",
      "   BaselineRF@0.50  0.878308   0.833333 0.188442 0.307377 0.796287 4729   30 646 150\n",
      "       BestRF@0.50  0.861926   0.525573 0.374372 0.437271 0.778746 4490  269 498 298\n",
      "BestRF@F2opt(0.33)  0.576418   0.230343 0.835427 0.361119 0.778746 2537 2222 131 665\n",
      "\n",
      "Classification report for BestRF at chosen threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.53      0.68      4759\n",
      "         1.0       0.23      0.84      0.36       796\n",
      "\n",
      "    accuracy                           0.58      5555\n",
      "   macro avg       0.59      0.68      0.52      5555\n",
      "weighted avg       0.85      0.58      0.64      5555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Imports =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, fbeta_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report, make_scorer\n",
    ")\n",
    "\n",
    "# ===== Assumes you already have x_train, x_test, y_train, y_test =====\n",
    "# If not, uncomment the split lines below (expects `data` with ABANDONED_CART target):\n",
    "# X = data.drop(columns=['ABANDONED_CART','CUSTOMER_ID'])\n",
    "# y = data['ABANDONED_CART']\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.30, random_state=12345, stratify=y\n",
    "# )\n",
    "\n",
    "# --- 1) One-hot encode categoricals, align columns, simple median impute ---\n",
    "x_train_enc = pd.get_dummies(x_train, drop_first=True)\n",
    "x_test_enc  = pd.get_dummies(x_test,  drop_first=True)\n",
    "x_test_enc  = x_test_enc.reindex(columns=x_train_enc.columns, fill_value=np.nan)\n",
    "medians = x_train_enc.median(numeric_only=True)\n",
    "x_train_enc = x_train_enc.fillna(medians)\n",
    "x_test_enc  = x_test_enc.fillna(medians)\n",
    "\n",
    "# --- 2) Baseline RF (no tuning) ---\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_base.fit(x_train_enc, y_train)\n",
    "y_proba_base = rf_base.predict_proba(x_test_enc)[:, 1]\n",
    "\n",
    "# --- 3) Grid search for best recall ---\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [None, 12, 20],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'class_weight': [None, 'balanced_subsample', 'balanced']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(recall_score),   # optimize recall\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gs.fit(x_train_enc, y_train)\n",
    "\n",
    "best_rf = gs.best_estimator_\n",
    "y_proba_best = best_rf.predict_proba(x_test_enc)[:, 1]\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(\"CV best recall:\", round(gs.best_score_, 4))\n",
    "\n",
    "# --- 4) Choose thresholds for evaluation ---\n",
    "# Always evaluate at default 0.50\n",
    "th_default = 0.50\n",
    "\n",
    "# Also pick threshold that maximizes F2 (recall-heavy)\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f2_vals = []\n",
    "for th in ths:\n",
    "    y_pred_th = (y_proba_best >= th).astype(int)\n",
    "    f2_vals.append(fbeta_score(y_test, y_pred_th, beta=2.0, zero_division=0))\n",
    "th_f2_opt = ths[int(np.argmax(f2_vals))]\n",
    "\n",
    "print(f\"Chosen F2-optimal threshold for best RF: {th_f2_opt:.3f}\")\n",
    "\n",
    "# --- 5) Utility to compute metrics & confusion counts at a threshold ---\n",
    "def eval_metrics(y_true, y_proba, th, label):\n",
    "    y_pred = (y_proba >= th).astype(int)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return {\n",
    "        \"Model@Threshold\": label,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"AUC\": auc,\n",
    "        \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp\n",
    "    }\n",
    "\n",
    "# --- 6) Build comparison table ---\n",
    "rows = []\n",
    "# Baseline RF @ 0.50\n",
    "rows.append(eval_metrics(y_test, y_proba_base, th_default, \"BaselineRF@0.50\"))\n",
    "\n",
    "# Best RF @ 0.50\n",
    "rows.append(eval_metrics(y_test, y_proba_best, th_default, \"BestRF@0.50\"))\n",
    "\n",
    "# Best RF @ F2-opt\n",
    "rows.append(eval_metrics(y_test, y_proba_best, th_f2_opt, f\"BestRF@F2opt({th_f2_opt:.2f})\"))\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "# Nicely formatted view\n",
    "metrics_cols = [\"Model@Threshold\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\", \"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "results_df = results_df[metrics_cols]\n",
    "print(\"\\n=== Comparison Table ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# --- 7) (Optional) Detailed classification report for the chosen setting ---\n",
    "# Pick your preferred row (e.g., F2-opt) to inspect:\n",
    "chosen_th = th_f2_opt\n",
    "y_pred_chosen = (y_proba_best >= chosen_th).astype(int)\n",
    "print(\"\\nClassification report for BestRF at chosen threshold:\")\n",
    "print(classification_report(y_test, y_pred_chosen, zero_division=0))\n",
    "\n",
    "# --- 8) (Optional) Show ROC AUC curves quickly (no plot libs required) ---\n",
    "# If you want the ROC curve visually, you can add matplotlib plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== XGBoost (core API) with early stopping + threshold tuning =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# ---- 0) One-hot encode & align (uses your existing x_train/x_test) ----\n",
    "x_train_enc = pd.get_dummies(x_train, drop_first=True)\n",
    "x_test_enc  = pd.get_dummies(x_test,  drop_first=True)\n",
    "x_test_enc  = x_test_enc.reindex(columns=x_train_enc.columns, fill_value=np.nan)\n",
    "\n",
    "# (Optional) Simple impute (XGB can handle NaNs, but this is explicit)\n",
    "medians = x_train_enc.median(numeric_only=True)\n",
    "x_train_enc = x_train_enc.fillna(medians)\n",
    "x_test_enc  = x_test_enc.fillna(medians)\n",
    "\n",
    "# ---- 1) Wrap in DMatrix ----\n",
    "dtrain = xgb.DMatrix(x_train_enc, label=y_train, feature_names=x_train_enc.columns.tolist())\n",
    "dvalid = xgb.DMatrix(x_test_enc,  label=y_test,  feature_names=x_test_enc.columns.tolist())\n",
    "\n",
    "# ---- 2) Class imbalance weight ----\n",
    "pos = int((y_train == 1).sum())\n",
    "neg = int((y_train == 0).sum())\n",
    "spw = neg / max(pos, 1)\n",
    "\n",
    "# ---- 3) Train with early stopping (AUC) ----\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"lambda\": 1.0,             # L2\n",
    "    \"alpha\": 0.0,              # L1\n",
    "    \"scale_pos_weight\": spw,   # handle imbalance\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# ---- 4) Predict using best_iteration (works on new XGB) ----\n",
    "best_iter = getattr(bst, \"best_iteration\", None)\n",
    "if best_iter is not None:\n",
    "    y_proba = bst.predict(dvalid, iteration_range=(0, best_iter + 1))\n",
    "else:\n",
    "    y_proba = bst.predict(dvalid)\n",
    "\n",
    "# Helper to print metrics neatly\n",
    "def show_metrics(y_true, y_pred, y_prob, label):\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"AUC      : {auc:.4f}\")\n",
    "    print(f\"CM -> TN:{tn} FP:{fp} FN:{fn} TP:{tp}\")\n",
    "\n",
    "# ---- 5) Metrics at default 0.50 ----\n",
    "y_pred_050 = (y_proba >= 0.50).astype(int)\n",
    "show_metrics(y_test, y_pred_050, y_proba, \"XGB (core) @ 0.50\")\n",
    "\n",
    "# ---- 6) Threshold sweep: maximize accuracy with recall >= 0.70 ----\n",
    "def sweep_thresholds(y_true, y_prob, thresholds):\n",
    "    rows = []\n",
    "    for th in thresholds:\n",
    "        yp = (y_prob >= th).astype(int)\n",
    "        acc  = accuracy_score(y_true, yp)\n",
    "        prec = precision_score(y_true, yp, zero_division=0)\n",
    "        rec  = recall_score(y_true, yp, zero_division=0)\n",
    "        f1   = f1_score(y_true, yp, zero_division=0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, yp).ravel()\n",
    "        rows.append({\"th\": th, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "                     \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "grid = np.linspace(0.05, 0.95, 91)\n",
    "th_df = sweep_thresholds(y_test, y_proba, grid)\n",
    "\n",
    "target_recall = 0.70\n",
    "candidates = th_df[th_df[\"recall\"] >= target_recall]\n",
    "best_row = candidates.sort_values(\"accuracy\", ascending=False).iloc[0] if not candidates.empty \\\n",
    "           else th_df.sort_values(\"recall\", ascending=False).iloc[0]\n",
    "best_th = float(best_row[\"th\"])\n",
    "\n",
    "print(\"\\nChosen threshold (max accuracy with recall ≥ {:.2f}): {:.3f}\".format(target_recall, best_th))\n",
    "print(best_row[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"tn\",\"fp\",\"fn\",\"tp\"]])\n",
    "\n",
    "# ---- 7) Metrics at chosen threshold ----\n",
    "y_pred_best = (y_proba >= best_th).astype(int)\n",
    "show_metrics(y_test, y_pred_best, y_proba, f\"XGB (core) @ {best_th:.3f}\")\n",
    "print(\"\\nClassification report at chosen threshold:\\n\",\n",
    "      classification_report(y_test, y_pred_best, zero_division=0))\n",
    "\n",
    "# ---- 8) Top 20 features (by gain) ----\n",
    "score = bst.get_score(importance_type=\"gain\")\n",
    "imp = (pd.DataFrame({\"feature\": list(score.keys()), \"gain\": list(score.values())})\n",
    "       .sort_values(\"gain\", ascending=False)\n",
    "       .head(20))\n",
    "print(\"\\nTop 20 XGB features by gain:\")\n",
    "print(imp.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6573dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'best_ntree_limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m\n\u001b[0;32m     45\u001b[0m bst \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     46\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m     47\u001b[0m     dtrain\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# --- Predictions/probabilities (use best_ntree_limit) ---\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(dvalid, ntree_limit\u001b[38;5;241m=\u001b[39mbst\u001b[38;5;241m.\u001b[39mbest_ntree_limit)\n\u001b[0;32m     56\u001b[0m y_pred_050 \u001b[38;5;241m=\u001b[39m (y_proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.50\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_metrics\u001b[39m(y_true, y_pred, y_prob, label):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'best_ntree_limit'"
     ]
    }
   ],
   "source": [
    "# ===== XGBoost (core API) with early stopping, robust across versions =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# --- One-hot encode & align (reuse your existing split) ---\n",
    "x_train_enc = pd.get_dummies(x_train, drop_first=True)\n",
    "x_test_enc  = pd.get_dummies(x_test,  drop_first=True)\n",
    "x_test_enc  = x_test_enc.reindex(columns=x_train_enc.columns, fill_value=np.nan)\n",
    "\n",
    "# Optional impute (XGBoost can handle NaN, but we can be explicit)\n",
    "medians = x_train_enc.median(numeric_only=True)\n",
    "x_train_enc = x_train_enc.fillna(medians)\n",
    "x_test_enc  = x_test_enc.fillna(medians)\n",
    "\n",
    "# --- DMatrix conversion (faster + stable API) ---\n",
    "dtrain = xgb.DMatrix(x_train_enc, label=y_train, feature_names=x_train_enc.columns.tolist())\n",
    "dvalid = xgb.DMatrix(x_test_enc,  label=y_test,  feature_names=x_test_enc.columns.tolist())\n",
    "\n",
    "# --- Imbalance weight ---\n",
    "pos = int((y_train == 1).sum())\n",
    "neg = int((y_train == 0).sum())\n",
    "spw = neg / max(pos, 1)\n",
    "\n",
    "# --- Params (AUC early stopping on valid) ---\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"lambda\": 1.0,      # L2\n",
    "    \"alpha\": 0.0,       # L1\n",
    "    \"scale_pos_weight\": spw,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# --- Predictions/probabilities (use best_ntree_limit) ---\n",
    "y_proba = bst.predict(dvalid, ntree_limit=bst.best_ntree_limit)\n",
    "y_pred_050 = (y_proba >= 0.50).astype(int)\n",
    "\n",
    "def show_metrics(y_true, y_pred, y_prob, label):\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1       : {f1:.4f}\")\n",
    "    print(f\"AUC      : {auc:.4f}\")\n",
    "    print(f\"CM -> TN:{tn} FP:{fp} FN:{fn} TP:{tp}\")\n",
    "\n",
    "show_metrics(y_test, y_pred_050, y_proba, \"XGB (core) @ 0.50\")\n",
    "\n",
    "# --- Threshold sweep: maximize accuracy with recall >= 0.70 ---\n",
    "def sweep_thresholds(y_true, y_prob, thresholds):\n",
    "    rows = []\n",
    "    for th in thresholds:\n",
    "        yp = (y_prob >= th).astype(int)\n",
    "        acc  = accuracy_score(y_true, yp)\n",
    "        prec = precision_score(y_true, yp, zero_division=0)\n",
    "        rec  = recall_score(y_true, yp, zero_division=0)\n",
    "        f1   = f1_score(y_true, yp, zero_division=0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, yp).ravel()\n",
    "        rows.append({\"th\": th, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "                     \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "grid = np.linspace(0.05, 0.95, 91)\n",
    "th_df = sweep_thresholds(y_test, y_proba, grid)\n",
    "\n",
    "target_recall = 0.70\n",
    "candidates = th_df[th_df[\"recall\"] >= target_recall]\n",
    "best_row = candidates.sort_values(\"accuracy\", ascending=False).iloc[0] if not candidates.empty \\\n",
    "           else th_df.sort_values(\"recall\", ascending=False).iloc[0]\n",
    "best_th = float(best_row[\"th\"])\n",
    "\n",
    "print(\"\\nChosen threshold (max accuracy with recall ≥ {:.2f}): {:.3f}\".format(target_recall, best_th))\n",
    "print(best_row[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"tn\",\"fp\",\"fn\",\"tp\"]])\n",
    "\n",
    "# --- Metrics at chosen threshold ---\n",
    "y_pred_best = (y_proba >= best_th).astype(int)\n",
    "show_metrics(y_test, y_pred_best, y_proba, f\"XGB (core) @ {best_th:.3f}\")\n",
    "print(\"\\nClassification report at chosen threshold:\\n\",\n",
    "      classification_report(y_test, y_pred_best, zero_division=0))\n",
    "\n",
    "# --- Top features ---\n",
    "# get_score returns dict of {feature_name: importance}; convert to DataFrame\n",
    "score = bst.get_score(importance_type=\"gain\")\n",
    "imp = (pd.DataFrame({\"feature\": list(score.keys()), \"gain\": list(score.values())})\n",
    "       .sort_values(\"gain\", ascending=False)\n",
    "       .head(20))\n",
    "print(\"\\nTop 20 XGB features by gain:\")\n",
    "print(imp.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
